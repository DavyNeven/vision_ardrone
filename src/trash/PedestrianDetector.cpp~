#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>
#include <sensor_msgs/image_encodings.h>
#include <opencv2/opencv.hpp>
#include <std_msgs/Empty.h>
#include "ardrone_autonomy/Navdata.h"
#include "geometry_msgs/Twist.h"
#include "Track.h"
#include <stdio.h>

using namespace cv;
using namespace std; 

const char *windowName = "Image window";

 ros::Publisher pub;
HOGDescriptor hog; 
Track track(0.5,0.00,0.000);


void imageCb(const sensor_msgs::ImageConstPtr& msg)
{
    cv_bridge::CvImagePtr cv_ptr;
    try
    {
      cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
    }
    catch (cv_bridge::Exception& e)
    {
      ROS_ERROR("cv_bridge exception: %s", e.what());
      return;
    }

    Mat img = cv_ptr->image; 
    Mat smallImg;
    float scale = img.cols / (float) 640;
    // Shrink image while keeping same aspect ratio.
    int scaledHeight = cvRound(img.rows/scale);
    resize(img, smallImg, Size(640, scaledHeight));
		

	vector<Rect> found, found_filtered;
        hog.detectMultiScale(smallImg, found, 0, Size(8,8), Size(0,0), 1.1, 0);
 
        size_t i, j;
        for (i=0; i<found.size(); i++)
        {
            Rect r = found[i];
            for (j=0; j<found.size(); j++)
                if (j!=i && (r & found[j])==r)
                    break;
            if (j==found.size())
                found_filtered.push_back(r);
        }
	//send only 1 box;
        for (i=0; i<found_filtered.size(); i++)
        {
	 		Rect r = found_filtered[i];
		   /* r.x += cvRound(r.width*0.1);
		    r.width = cvRound(r.width*0.8);
		    r.y += cvRound(r.height*0.06);
		    r.height = cvRound(r.height*0.9);*/
 			rectangle(smallImg, r, cv::Scalar(0,0,255), 2);
	}
	    if(found_filtered.size()) // person detected!
	    {
		    Rect r = found_filtered[0];
		   /* r.x += cvRound(r.width*0.1);
		    r.width = cvRound(r.width*0.8);
		    r.y += cvRound(r.height*0.06);
		    r.height = cvRound(r.height*0.9);*/
		    track.predict_update(&r);
		   // rectangle(img,r, cv::Scalar(0,255,0), 2);
		    geometry_msgs::Twist pos; 
		    Rect tr = track.getBoundingBox();
		    pos.linear.x = tr.x; pos.linear.y=tr.y; pos.linear.z = 0; 
		    pos.angular.x = tr.width; pos.angular.y = tr.height; pos.angular.z = 0; 
		    pub.publish(pos); 
	    }
	    else if(track.initialized)
	    {
		    geometry_msgs::Twist pos; 
		    Rect tr = track.getBoundingBox();
		    pos.linear.x = tr.x; pos.linear.y=tr.y; pos.linear.z = 0; 
		    pos.angular.x = tr.width; pos.angular.y = tr.height; pos.angular.z = 0; 
		    pub.publish(pos); 
		    track.predict_update();
	    }
             
	     rectangle(smallImg, track.getBoundingBox(), cv::Scalar(255,0,0), 2);
	//}   

    
    imshow(windowName, smallImg);
    waitKey(1);
}


int main(int argc, char** argv)
{
	ros::init(argc, argv, "person_detector");
	ros::NodeHandle nh; 
	image_transport::ImageTransport it(nh); 
	image_transport::Subscriber img_sub; 
	img_sub = it.subscribe("/ardrone/image_raw", 1,&imageCb);
	pub = nh.advertise<geometry_msgs::Twist>(
		"/pedestrian/position", 1000);
	hog.setSVMDetector(cv::HOGDescriptor::getDefaultPeopleDetector());

	cv::namedWindow(windowName);
	ros::spin(); 
	return 0; 
}
